{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60b7cfe",
   "metadata": {},
   "source": [
    "**Problem Statement**\n",
    "\n",
    "This project understands how hotel bookings cancellations are affected by factors such as whether the customer stays in weekend nights, has children, is a repeated guest, has previous cancellations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b4fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report # Useful for a detailed report\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#import xgboost as xgb\n",
    "\n",
    "import time\n",
    "from typing import Tuple, List\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da29de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefe3e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hotel_bookings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded dataset with shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhotel_bookings.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m(file_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m [pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded dataset with shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32me:\\Projects\\HotelCancellation\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Projects\\HotelCancellation\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\Projects\\HotelCancellation\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Projects\\HotelCancellation\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\Projects\\HotelCancellation\\venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hotel_bookings.csv'"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "def load_data(file_path: str) -> [pd.DataFrame]:\n",
    "    df = pd.read_csv(file_path)\n",
    "    logging.info(f\"Loaded dataset with shape: {df.shape}\")\n",
    "    return df\n",
    "    \n",
    "df = load_data(\"hotel_bookings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02d10055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Drop the duplicates - keeping the first occurence, then reset the index\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8bff1",
   "metadata": {},
   "source": [
    "**Prepare X and y variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2f5f3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87396, 31)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"is_canceled\"], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a639dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87396,)\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: is_canceled, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df[\"is_canceled\"]\n",
    "print(y.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92b4faae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61177, 31)\n",
      "(26219, 31)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "\n",
    "def split_data(X:pd.DataFrame, y:pd.Series)->Tuple:\n",
    "    \"\"\"\n",
    "    Split the data into train and test sets\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4c859",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf5e3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "2025-05-13 17:05:13,664 - INFO - Data feature engineering completed successfully\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(X_train:pd.DataFrame, X_test:pd.DataFrame)->Tuple:\n",
    "    \"\"\"\n",
    "    Preprocess the datasets. Start with feature selection: numerical and categorical columns\n",
    "    \"\"\"\n",
    "    numerical_cols = X_train.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=\"object\").columns.tolist()\n",
    "    high_cardinality_features = [feature for feature in categorical_cols if X_train[feature].nunique()>8]\n",
    "    \n",
    "    # Create feature engineered features\n",
    "    for df in [X_train, X_test]:\n",
    "        \n",
    "        df[\"hotel_stay\"] = df[\"stays_in_weekend_nights\"] + df[\"stays_in_week_nights\"]\n",
    "        \n",
    "        df[\"total_guests\"] = df[\"adults\"] + df[\"children\"] + df[\"babies\"]\n",
    "        \n",
    "        # calculates previous cancellation rate to measure how often a returning customer has canceled in the past\n",
    "        df[\"prev_cancellation_rate\"] = df[\"previous_cancellations\"] / (df[\"previous_cancellations\"] + \n",
    "                                                                       df[\"previous_bookings_not_canceled\"]).replace(0, 1)\n",
    "        \n",
    "        month_map = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "                     'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "                    }\n",
    "        \n",
    "        df['arrival_date_month_num'] = df['arrival_date_month'].map(month_map)\n",
    "        \n",
    "        df[\"arrival_date\"] = pd.to_datetime(df[\"arrival_date_year\"].astype(str) + '-' +\n",
    "                                     df[\"arrival_date_month_num\"].astype(str) + '-' +\n",
    "                                       df[\"arrival_date_day_of_month\"].astype(str), errors='coerce')\n",
    "        \n",
    "        df[\"arrival_day_of_week\"] = df[\"arrival_date\"].dt.day_name()\n",
    "        \n",
    "    # Drop columns that won't add any predictive power to the model - as per the EDA\n",
    "    cols_drop = [\"arrival_date_month\", \"arrival_date\", \"company\", \"agent\", \"reservation_status\", \"reservation_status_date\"]\n",
    "    X_train.drop(columns = cols_drop, inplace=True)\n",
    "    X_test.drop(columns = cols_drop, inplace=True)\n",
    "    \n",
    "    # Update the numerical and categorical columns\n",
    "    numerical_cols = [col for col in numerical_cols if col not in cols_drop]\n",
    "    numerical_cols += [\"hotel_stay\", \"total_guests\", \"prev_cancellation_rate\", \"arrival_date_month_num\"]\n",
    "    \n",
    "    categorical_cols = [col for col in categorical_cols if col not in cols_drop and col not in high_cardinality_features]\n",
    "    categorical_cols += [\"arrival_day_of_week\"]\n",
    "    \n",
    "    high_cardinality_features = [col for col in high_cardinality_features if col not in cols_drop]\n",
    "    \n",
    "    # Log transform the adr column\n",
    "    X_train[\"adr\"] = np.log1p(X_train[\"adr\"])\n",
    "    X_test[\"adr\"] = np.log1p(X_test[\"adr\"])\n",
    "    \n",
    "    logging.info(\"Data feature engineering completed successfully\")\n",
    "    return X_train, X_test, numerical_cols, categorical_cols, high_cardinality_features\n",
    "    \n",
    "    \n",
    "    \n",
    "X_train, X_test, numerical_cols, categorical_cols, high_cardinality_features = feature_engineering(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56240e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61177, 31)\n",
      "(26219, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  \n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4df25959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead_time', 'arrival_date_year', 'arrival_date_week_number', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list', 'adr', 'required_car_parking_spaces', 'total_of_special_requests', 'hotel_stay', 'total_guests', 'prev_cancellation_rate', 'arrival_date_month_num']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "054eebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hotel', 'meal', 'market_segment', 'distribution_channel', 'deposit_type', 'customer_type', 'arrival_day_of_week']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c1fdf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'reserved_room_type', 'assigned_room_type']\n"
     ]
    }
   ],
   "source": [
    "print(high_cardinality_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af714e9",
   "metadata": {},
   "source": [
    "**Build a preprocessor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7ef5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(numerical_cols, categorical_cols, high_cardinality_features)->ColumnTransformer:\n",
    "    \"\"\"\n",
    "    Build a preprocessing pipeline that will handle all the preprocessing: imputation, scaling\n",
    "    \"\"\"\n",
    "    high_card_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"target_encoder\", TargetEncoder())\n",
    "    ])\n",
    "    \n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ])\n",
    "    \n",
    "    num_transformer = Pipeline(steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"high_card\", high_card_transformer, high_cardinality_features),\n",
    "        (\"cat\", cat_transformer, categorical_cols),\n",
    "        (\"num\", num_transformer, numerical_cols)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71a63959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('high_card',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='Unknown',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('target_encoder',\n",
       "                                                  TargetEncoder())]),\n",
       "                                 ['country', 'reserved_room_type',\n",
       "                                  'assigned_room_type']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='Unknown',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown...\n",
       "                                  'arrival_date_day_of_month',\n",
       "                                  'stays_in_weekend_nights',\n",
       "                                  'stays_in_week_nights', 'adults', 'children',\n",
       "                                  'babies', 'is_repeated_guest',\n",
       "                                  'previous_cancellations',\n",
       "                                  'previous_bookings_not_canceled',\n",
       "                                  'booking_changes', 'days_in_waiting_list',\n",
       "                                  'adr', 'required_car_parking_spaces',\n",
       "                                  'total_of_special_requests', 'hotel_stay',\n",
       "                                  'total_guests', 'prev_cancellation_rate',\n",
       "                                  'arrival_date_month_num'])])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = build_preprocessor(numerical_cols, categorical_cols, high_cardinality_features)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "379d511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification_models(X_train, y_train, preprocessor, random_state=42):\n",
    "    \"\"\"\n",
    "    Train different classification models for comparison using GridSearchCV.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        preprocessor (ColumnTransformer): The preprocessing pipeline.\n",
    "        random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: A tuple containing:\n",
    "            - models (dict): Dictionary of trained best models.\n",
    "            - results (dict): Dictionary of training results (best params, best score, train time).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define classification models to train and their parameter grids\n",
    "    models_config = {\n",
    "        \"LogisticRegression\": {\n",
    "            \"model\": LogisticRegression(random_state=random_state, solver='liblinear'),\n",
    "            \"params\": {\n",
    "                \"C\": [0.1, 1.0, 10.0],\n",
    "                \"penalty\": ['l1', 'l2']\n",
    "            }\n",
    "        },\n",
    "        \"RandomForestClassifier\": {\n",
    "            \"model\": RandomForestClassifier(random_state=random_state),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [100, 200], \n",
    "                \"max_depth\": [5, 10, None], \n",
    "                \"min_samples_split\": [2, 5]\n",
    "            }\n",
    "        },\n",
    "        \"GradientBoostingClassifier\": {\n",
    "            \"model\": GradientBoostingClassifier(random_state=random_state),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [100, 150], \n",
    "                \"learning_rate\": [0.05, 0.1],\n",
    "                \"max_depth\": [3, 4]\n",
    "            }\n",
    "        },\n",
    "        \"XGBClassifier\": {\n",
    "            \"model\": xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=random_state),\n",
    "            \"params\": {\n",
    "                'n_estimators': [100, 150],\n",
    "                'learning_rate': [0.05, 0.1],\n",
    "                'max_depth': [3, 4],\n",
    "                'colsample_bytree': [0.7, 0.8]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    models = {}\n",
    "\n",
    "    # Define the scoring metric - ROC AUC is good for imbalanced classification\n",
    "    roc_auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "    # Train each model\n",
    "    for name, config in models_config.items():\n",
    "        start_time = time.time()\n",
    "        logging.info(f\"Training {name} model...\")\n",
    "\n",
    "        # Create the pipeline including preprocessing and the model\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", config[\"model\"])\n",
    "        ])\n",
    "\n",
    "        # Adjust parameter grid keys to match the pipeline step name ('model')\n",
    "        param_grid = {f'model__{param}': values for param, values in config['params'].items()}\n",
    "\n",
    "        # Set up GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=KFold(n_splits=5, shuffle=True, random_state=random_state),\n",
    "            scoring=roc_auc_scorer,\n",
    "            verbose=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit the model\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Store the results\n",
    "        models[name] = grid_search.best_estimator_\n",
    "        results[name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_roc_auc_score': grid_search.best_score_, # Best score is now ROC AUC\n",
    "            'train_time': time.time() - start_time\n",
    "        }\n",
    "\n",
    "        logging.info(f\"{name} training completed in {results[name]['train_time']:.2f} seconds\")\n",
    "        logging.info(f\"Best parameters: {results[name]['best_params']}\")\n",
    "        logging.info(f\"Best CV ROC AUC: {results[name]['best_roc_auc_score']:.5f}\")\n",
    "\n",
    "    return models, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a5dc2b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 17:52:58,770 - INFO - Training LogisticRegression model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 18:07:08,581 - INFO - LogisticRegression training completed in 849.81 seconds\n",
      "2025-05-13 18:07:08,582 - INFO - Best parameters: {'model__C': 10.0, 'model__penalty': 'l1'}\n",
      "2025-05-13 18:07:08,582 - INFO - Best CV ROC AUC: 0.83146\n",
      "2025-05-13 18:07:08,583 - INFO - Training RandomForestClassifier model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 18:18:54,493 - INFO - RandomForestClassifier training completed in 705.91 seconds\n",
      "2025-05-13 18:18:54,494 - INFO - Best parameters: {'model__max_depth': None, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n",
      "2025-05-13 18:18:54,495 - INFO - Best CV ROC AUC: 0.89764\n",
      "2025-05-13 18:18:54,496 - INFO - Training GradientBoostingClassifier model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 18:39:00,449 - INFO - GradientBoostingClassifier training completed in 1205.95 seconds\n",
      "2025-05-13 18:39:00,452 - INFO - Best parameters: {'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__n_estimators': 150}\n",
      "2025-05-13 18:39:00,454 - INFO - Best CV ROC AUC: 0.89230\n",
      "2025-05-13 18:39:00,455 - INFO - Training XGBClassifier model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:41:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-05-13 18:41:30,802 - INFO - XGBClassifier training completed in 150.35 seconds\n",
      "2025-05-13 18:41:30,803 - INFO - Best parameters: {'model__colsample_bytree': 0.7, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__n_estimators': 150}\n",
      "2025-05-13 18:41:30,806 - INFO - Best CV ROC AUC: 0.89155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Results ---\n",
      "\n",
      "Model: LogisticRegression\n",
      "  Best CV ROC AUC: 0.83146\n",
      "  Best Params: {'model__C': 10.0, 'model__penalty': 'l1'}\n",
      "  Train Time: 849.81 seconds\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "  Best CV ROC AUC: 0.89764\n",
      "  Best Params: {'model__max_depth': None, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n",
      "  Train Time: 705.91 seconds\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "  Best CV ROC AUC: 0.89230\n",
      "  Best Params: {'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__n_estimators': 150}\n",
      "  Train Time: 1205.95 seconds\n",
      "\n",
      "Model: XGBClassifier\n",
      "  Best CV ROC AUC: 0.89155\n",
      "  Best Params: {'model__colsample_bytree': 0.7, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__n_estimators': 150}\n",
      "  Train Time: 150.35 seconds\n"
     ]
    }
   ],
   "source": [
    "# call the classification training function\n",
    "trained_models, training_results = train_classification_models(X_train, y_train, preprocessor)\n",
    "\n",
    "print(\"\\n--- Training Results ---\")\n",
    "for name, res in training_results.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"  Best CV ROC AUC: {res['best_roc_auc_score']:.5f}\")\n",
    "    print(f\"  Best Params: {res['best_params']}\")\n",
    "    print(f\"  Train Time: {res['train_time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_models(models: Dict[str, Any], X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Evaluate trained classification models on the test set.\n",
    "\n",
    "    Args:\n",
    "        models (Dict[str, Any]): Dictionary of trained models (e.g., from train_classification_models).\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, Any]]: Dictionary containing evaluation metrics for each model.\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    logging.info(\"Starting model evaluation on the test set...\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        logging.info(f\"Evaluating {name}...\")\n",
    "\n",
    "        try:\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate ROC AUC-Make probability predictions\n",
    "    \n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                 # Get probabilities for the positive class (class 1)\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            else:\n",
    "                # For models without predict_proba, ROC AUC is not needed\n",
    "                y_pred_proba = None\n",
    "                roc_auc = np.nan \n",
    "\n",
    "\n",
    "            # Calculate the other metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0) # zero_division=0 handles cases with no positive predictions\n",
    "            recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            # Store results\n",
    "            evaluation_results[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': roc_auc,\n",
    "                'confusion_matrix': conf_matrix.tolist(), # Convert numpy array to list for easier storage/printing\n",
    "            }\n",
    "\n",
    "            logging.info(f\"{name} evaluation complete.\")\n",
    "            logging.info(f\"  Accuracy: {accuracy:.4f}\")\n",
    "            logging.info(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "            #logging.info(f\"  F1 Score: {f1_score:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error evaluating model {name}: {e}\")\n",
    "            evaluation_results[name] = {'error': str(e)}\n",
    "        \n",
    "    best_model_name = max(evaluation_results, key=lambda name: evaluation_results[name]['f1_score'])\n",
    "    best_model = trained_models[best_model_name]\n",
    "\n",
    "    logging.info(\"Model evaluation completed.\")\n",
    "    \n",
    "    logging.info(f\"Best performing model: {best_model_name} with F1 Score: {evaluation_results[best_model_name]['f1_score']:.5f}\")\n",
    "    \n",
    "    return evaluation_results, best_model_name, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2081816",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluation_results, best_model_name, best_model = evaluate_classification_models(trained_models, X_test, y_test)\n",
    "\n",
    "print(\"\\n--- Test Set Evaluation Results ---\")\n",
    "for name, res in test_evaluation_results.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    if 'error' in res:\n",
    "        print(f\"  Evaluation Error: {res['error']}\")\n",
    "    else:\n",
    "        print(f\"  Accuracy: {res['accuracy']:.4f}\")\n",
    "        print(f\"  ROC AUC: {res['roc_auc']:.4f}\")\n",
    "        print(f\"  Precision: {res['precision']:.4f}\")\n",
    "        print(f\"  Recall: {res['recall']:.4f}\")\n",
    "        print(f\"  F1 Score: {res['f1_score']:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{np.array(res['confusion_matrix'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
